{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Loop\n",
    "\n",
    "[A1 - First trial selection](#A1)\n",
    "\n",
    "[A3 - Order of presentation during training](#A3)\n",
    "\n",
    "[A4 - Performance during training](#A4)\n",
    "\n",
    "[A5 - Learning Progress](#A5)\n",
    "\n",
    "[A6 - Relative performance during training](#A6)\n",
    "\n",
    "[A7 - Relative Learning Progress](#A7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rcParams\n",
    "import pandas as pd\n",
    "import warnings\n",
    "#import seaborn as sns\n",
    "from scipy.stats import beta\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.html.widgets import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "rcParams.update({'font.size': 15})\n",
    "#plt.style.use('ggplot')\n",
    "#plt.style.use('seaborn-dark-palette')\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "float_formatter = lambda x: \"%.2f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "import io\n",
    "from IPython.nbformat import current\n",
    "\n",
    "def execute_notebook(nbfile):\n",
    "    \n",
    "    with io.open(nbfile) as f:\n",
    "        nb = current.read(f, 'json')\n",
    "    \n",
    "    ip = get_ipython()\n",
    "    \n",
    "    for cell in nb.worksheets[0].cells:\n",
    "        if cell.cell_type != 'code':\n",
    "            continue\n",
    "        ip.run_cell(cell.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load per trial data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'free']\n",
      "[b'free', b'train']\n",
      "[b'free', b'test', b'train']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"431.24999357387435\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_notebook(\"Preprocessing.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = 4\n",
    "catLab = ['1D', 'I1D', '2D', 'R']\n",
    "\n",
    "usersF = np.shape(np.unique(csvIntF[:,0]))[0]\n",
    "# For free exploration with Training\n",
    "usersFT = np.shape(np.unique(csvIntFT[:,0]))[0]\n",
    "usersFTI = np.shape(np.unique(informed[:,0]))[0]\n",
    "usersFTU = usersFT-usersFTI\n",
    "# For strategic learning\n",
    "usersS = np.shape(np.unique(csvIntS[:,0]))[0]\n",
    "usersSI = np.shape(np.unique(informedSE[:,0]))[0]\n",
    "usersSU = usersS-usersSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#user(0), cat-task complexity(1), # task selec(2), % sele(3), # correct on task(4), % correct(5), answers(7:12)\\nfree = np.loadtxt('../generated-data/free-free.txt')\\nprint('Free Exploration - general metrics loaded')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free Exploration with Training - general metrics loaded\n",
      "Strategic Learning - general metrics loaded\n"
     ]
    }
   ],
   "source": [
    "execute_notebook(\"Preprocessing-Stack Data.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./combined_free.pkl', 'wb') as file:\n",
    "    pickle.dump(freeT, file)\n",
    "with open('./combined_strat.pkl', 'wb') as file:\n",
    "    pickle.dump(stra, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split by information (free exp with training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user(0), cond(1) cat-task complexity(2), # task selec(3), % sele(4), # correct on task(5), % correct(6), \n",
    "#answers(7:12)\n",
    "\n",
    "# Split by users that received information about the existence of a random task and those that didn't\n",
    "informedFT = freeT[freeT[:,1]==0]\n",
    "uninformedFT = freeT[freeT[:,1]==1]\n",
    "#print(spilot[-1,:])\n",
    "# Remove first column \n",
    "freeT = np.delete(freeT, 1, axis=1)\n",
    "informedFT = np.delete(informedFT, 1, axis=1)\n",
    "uninformedFT = np.delete(uninformedFT, 1, axis=1)\n",
    "#free = np.delete(free, 1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split by information (strategic learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by users that received information about the existence of a random task and those that didn't\n",
    "informedS = stra[stra[:,1]==0]\n",
    "uninformedS = stra[stra[:,1]==1]\n",
    "#print(spilot[-1,:])\n",
    "# Remove column (condition)\n",
    "stra = np.delete(stra, 1, axis=1)\n",
    "informedS = np.delete(informedS, 1, axis=1)\n",
    "uninformedS = np.delete(uninformedS, 1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='A1'></a>\n",
    "## A1 - First trial selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkFirstOption(arr, usersArr, checkIncomplete=False):\n",
    "    firstSelec = []\n",
    "    incomplete = []\n",
    "    for u in range(usersArr):\n",
    "        # If it's necessary to check those that didn't explore all tasks (e.g. free exploration only)\n",
    "        if checkIncomplete:\n",
    "            questions = arr[u]\n",
    "            # Count number of times a task was selected\n",
    "            task, ctask = np.unique(questions[:,1], return_counts=True)\n",
    "\n",
    "            # Check if it explored all tasks\n",
    "            if len(task) < 4:\n",
    "                incomplete.append(u)\n",
    "            else:\n",
    "                firstSelec.append(arr[u][0,1])\n",
    "        else:\n",
    "            firstSelec.append(arr[u][0,1])\n",
    "            \n",
    "    # Return also a list of people who didn't explore all tasks\n",
    "    return np.asarray(firstSelec), incomplete\n",
    "    \n",
    "def plotFirstOption(arr, usersArr, label, checkIncomplete=False):\n",
    "    firstSelec, _ = checkFirstOption(arr, usersArr, checkIncomplete)\n",
    "    ind = np.arange(tasks)  # the x locations for the groups\n",
    "    width = 0.35       # the width of the bars\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    plt.hist(firstSelec, bins=np.arange(5), normed=True, edgecolor='black', linewidth=1.2)\n",
    "    ax.set_title(''.join(['Task selection on the first trial | ', label]))\n",
    "    ax.set_ylabel('Proportion')\n",
    "    #ax.set_xlabel('t')\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels(('1D', 'I1D', '2D', 'R'))\n",
    "    ax.set_ylim([0,0.4])\n",
    "\n",
    "#plotFirstOption(splitCsvFTE, usersFT, 'Train+Free Exp (All)')\n",
    "\n",
    "plotFirstOption(splitCsvFTI, usersFTI, 'Train+Free Exp (Informed)')\n",
    "plotFirstOption(splitCsvFTU, usersFTU, 'Train+Free Exp (Uninformed)')\n",
    "plotFirstOption(splitCsvF, usersF, 'Free Exp', checkIncomplete=True)\n",
    "plotFirstOption(splitCsvSU, usersSU, 'Strategic (Uninformed)')\n",
    "plotFirstOption(splitCsvSI, usersSI, 'Strategic (Informed)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='A3'></a>\n",
    "## A3 - Order of presentation during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A3. Order of presentation during training: % ppl who selected the first task they saw during training, \n",
    "#the 2nd task, the 3rd, and the 4th. We may see a uniform distributions, or peaks at 1 and 4. \n",
    "\n",
    "#ids, informed, phases, categories, correct\n",
    "# Split by informed or uninformed\n",
    "a3FTI = csvIntFT[csvIntFT[:,1] == 0,:]\n",
    "a3FTU = csvIntFT[csvIntFT[:,1] == 1,:]\n",
    "# Split by user\n",
    "splita3FTI = [a3FTI[a3FTI[:,0]==i] for i in np.unique(a3FTI[:,0])]\n",
    "splita3FTU = [a3FTU[a3FTU[:,0]==i] for i in np.unique(a3FTU[:,0])]\n",
    "\n",
    "a3SI = csvIntS[csvIntS[:,1] == 0,:]\n",
    "a3SU = csvIntS[csvIntS[:,1] == 1,:]\n",
    "# Split by user\n",
    "splita3SI = [a3SI[a3SI[:,0]==i] for i in np.unique(a3SI[:,0])]\n",
    "splita3SU = [a3SU[a3SU[:,0]==i] for i in np.unique(a3SU[:,0])]\n",
    "\n",
    "def getFirstSelecOrder(arr, usersArr, strategic=False):\n",
    "    if strategic:\n",
    "        trVal = 2\n",
    "    else:\n",
    "        trVal = 1\n",
    "    orderSelec = []\n",
    "    for u in range(usersArr):\n",
    "        tmp = arr[u]\n",
    "        # Get only training part\n",
    "        # for strategic learning this should be 2\n",
    "        tmpPhase = tmp[tmp[:,2] == trVal,:]\n",
    "        # Pass task column and get order indices then get order\n",
    "        orderIndex = np.unique(tmpPhase[:,3], return_index=True)[1]\n",
    "        orderTaskUser = [tmpPhase[ind, 3] for ind in sorted(orderIndex)]\n",
    "        # Get only exploration part\n",
    "        tmpPhase = tmp[tmp[:,2] == 0,:]\n",
    "        firstSelec = tmpPhase[0,3]\n",
    "        # Match that first selection to the order in which it showed up during training\n",
    "        orderTrain = np.where(orderTaskUser == firstSelec)[0][0]\n",
    "        #print(orderTaskUser, firstSelec, orderTrain)\n",
    "        orderSelec.append(orderTrain)\n",
    "    return orderSelec\n",
    "\n",
    "def plotFirstSelecOrder(arr, usersArr, label, strategic=False):\n",
    "    orderSelec = getFirstSelecOrder(arr, usersArr, strategic)\n",
    "    #print(np.shape(orderSelec), orderSelec)\n",
    "    \n",
    "    ind = np.arange(tasks)  # the x locations for the groups\n",
    "    width = 0.35       # the width of the bars\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    plt.hist(orderSelec, bins=np.arange(5), normed=True, edgecolor='black', linewidth=1.2)\n",
    "    ax.set_title(''.join(['Task selection based on order of presentation during training | ', label]))\n",
    "    ax.set_ylabel('Proportion')\n",
    "    #ax.set_xlabel('t')\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels(('1st', '2nd', '3rd', '4th'))\n",
    "    ax.set_ylim([0,0.4])\n",
    "\n",
    "plotFirstSelecOrder(splita3FTI, usersFTI, 'Train+Free Exp (Informed)')\n",
    "plotFirstSelecOrder(splita3FTU, usersFTU, 'Train+Free Exp (Uninformed)')\n",
    "plotFirstSelecOrder(splita3SI, usersSI, 'Strategic (Informed)')\n",
    "plotFirstSelecOrder(splita3SU, usersSU, 'Strategic (Uninformed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='A4'></a>\n",
    "## A4 - Performance during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A4. Performance during training: calculate %correct during the 15 training trials, bin the percentages, \n",
    "#and plot the % of ppl who selected a task with the PC in each bin. \n",
    "\n",
    "#user(0), cat-task complexity(1), # task selec(2), % sele(3), # correct on task(4), % correct(5), answers(6:11)\n",
    "# # correct (5), % clection according to the order of presentation during trainingorrect (6)\n",
    "\n",
    "# Split those informed and those uninformed. (col 1)\n",
    "ift = freeTTr[freeTTr[:,1]==0,:]\n",
    "uft = freeTTr[freeTTr[:,1]==1,:]\n",
    "istr = straTr[straTr[:,1]==0,:]\n",
    "ustr = straTr[straTr[:,1]==1,:]\n",
    "\n",
    "# Get task first selections\n",
    "selFTI = checkFirstOption(splitCsvFTI, usersFTI)\n",
    "selFTU = checkFirstOption(splitCsvFTU, usersFTU)\n",
    "selSI = checkFirstOption(splitCsvSI, usersSI)\n",
    "selSU = checkFirstOption(splitCsvSU, usersSU)\n",
    "\n",
    "# Get training pc of the first task selected\n",
    "def checkPerformance(arr, firstSelec):\n",
    "    usersArr = len(np.unique(arr[:,0]))\n",
    "    # Split by user\n",
    "    splitArr = [arr[arr[:,0]==i] for i in np.unique(arr[:,0])]\n",
    "    # Stores percentage correct during training of the task that later on was selected first on free exploration\n",
    "    pcTrain = []\n",
    "    # Go through every user and only extract the PC of the first task selected\n",
    "    for u in range(usersArr):\n",
    "        sub = splitArr[u]\n",
    "        # get only % correct of the row that corresponds to first selection\n",
    "        tmprow = sub[sub[:,2] == firstSelec[0].tolist()[u],6]\n",
    "        pcTrain.append(tmprow[0])\n",
    "    return pcTrain\n",
    "\n",
    "def plotPerformance(arr, firstSelec, label):\n",
    "    \n",
    "    performance = checkPerformance(arr, firstSelec)\n",
    "    \n",
    "    # Create bins (0 - 1 in 0.1 steps)\n",
    "    binsPC = np.linspace(0,1.1,12)\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    # Normalize to sum 1\n",
    "    weights = np.ones_like(performance)/len(performance)\n",
    "    plt.hist(performance, bins=binsPC, weights=weights, edgecolor='black', linewidth=1.2)\n",
    "    \n",
    "    #plt.hist(performance, bins=binsPC, edgecolor='black', linewidth=1.2)\n",
    "    ax.set_title(''.join(['Task selection on the first trial wrt PC | ', label]))\n",
    "    ax.set_ylabel('Proportion')\n",
    "    ax.set_ylim([0,0.32])\n",
    "\n",
    "        \n",
    "# Verification\n",
    "plotPerformance(ift,selFTI, 'Train+Free Exp (Informed)')\n",
    "plotPerformance(uft,selFTU, 'Train+Free Exp (Uninformed)')\n",
    "plotPerformance(istr,selSI, 'Strategic (Informed)')\n",
    "plotPerformance(ustr,selSU, 'Strategic (Uninformed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='A6'></a>\n",
    "## A6 - Relative performance during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A6. Relative performance during training: for each participant, take the value representing the PC for \n",
    "#each task during training, and normalize it by the mean PC across all 4 tasks. Plot the % of ppl who \n",
    "#selected a task as a function of its normalized PC.\n",
    "\n",
    "# Get relative training pc of the first task selected\n",
    "def checkRelativePerformance(arr, firstSelec):\n",
    "    usersArr = len(np.unique(arr[:,0]))\n",
    "    # Split by user\n",
    "    splitArr = [arr[arr[:,0]==i] for i in np.unique(arr[:,0])]\n",
    "    # Stores percentage correct during training of the task that later on was selected first on free exploration\n",
    "    # Normalized\n",
    "    pcTrain = []\n",
    "    # Go through every user and only extract the PC of the first task selected\n",
    "    for u in range(usersArr):\n",
    "        sub = splitArr[u]\n",
    "        # get only % correct of the row that corresponds to first selection\n",
    "        tmprow = sub[sub[:,2] == firstSelec[0].tolist()[u],6]\n",
    "        # get % correct of all tasks and calculate mean\n",
    "        pcNorm = np.mean(sub[:,6])\n",
    "        # Append normalized pc\n",
    "        pcTrain.append(tmprow[0]/pcNorm)\n",
    "    return pcTrain\n",
    "\n",
    "def plotRelativePerformance(arr, firstSelec, label):\n",
    "    \n",
    "    performance = checkRelativePerformance(arr, firstSelec)\n",
    "    \n",
    "    # Create bins (0 - 1 in 0.1 steps)\n",
    "    binsPC = np.linspace(0,2.1,22)\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    # Normalize to sum 1\n",
    "    weights = np.ones_like(performance)/len(performance)\n",
    "    plt.hist(performance, bins=binsPC, weights=weights, edgecolor='black', linewidth=1.2)\n",
    "    \n",
    "    #plt.hist(performance, bins=binsPC, edgecolor='black', linewidth=1.2)\n",
    "    ax.set_title(''.join(['Task selection on the first trial wrt relative PC | ', label]))\n",
    "    ax.set_ylabel('Proportion')\n",
    "    ax.set_ylim([0,0.2])\n",
    "    \n",
    "plotRelativePerformance(ift,selFTI, 'Train+Free Exp (Informed)')\n",
    "plotRelativePerformance(uft,selFTU, 'Train+Free Exp (Uninformed)')\n",
    "plotRelativePerformance(istr,selSI, 'Strategic (Informed)')\n",
    "plotRelativePerformance(ustr,selSU, 'Strategic (Uninformed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='A5'></a>\n",
    "## A5 - Learning Progress\n",
    "\n",
    "#### Additional Preprocessing (Free Exploration with Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load behavioral trajectories (csvIntFT)\n",
    "# Get only those in training phase\n",
    "csvIntFTT = csvIntFT[csvIntFT[:,2]==1]\n",
    "# Get a copy for splitting by condition (below)\n",
    "csvIntFTTCond = csvIntFTT.copy()\n",
    "\n",
    "# Remove phase column (2) (and for now also the condition column (1))\n",
    "csvIntFTT = np.delete(csvIntFTT, (1,2), axis=1)\n",
    "\n",
    "# Split by condition\n",
    "# Get rid of phase column\n",
    "csvIntFTTCond = np.delete(csvIntFTTCond, 2, axis = 1)\n",
    "# Split by informed/uninformed\n",
    "informedFTT = csvIntFTTCond[csvIntFTTCond[:,1]==0]\n",
    "uninformedFTT = csvIntFTTCond[csvIntFTTCond[:,1]==1]\n",
    "informedFTT = np.delete(informedFTT, 1, axis=1)\n",
    "uninformedFTT = np.delete(uninformedFTT, 1, axis=1)\n",
    "# Split by user\n",
    "splitInfFTT = [informedFTT[informedFTT[:,0]==i] for i in np.unique(informedFTT[:,0])]\n",
    "splitUniFTT = [uninformedFTT[uninformedFTT[:,0]==i] for i in np.unique(uninformedFTT[:,0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Preprocessing (Strategic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load behavioral trajectories (csvIntFT)\n",
    "# Get only those in training phase\n",
    "csvIntST = csvIntS[csvIntS[:,2]==1]\n",
    "# Get a copy for splitting by condition (below)\n",
    "csvIntSTCond = csvIntST.copy()\n",
    "\n",
    "# Remove phase column (2) (and for now also the condition column (1))\n",
    "csvIntST = np.delete(csvIntST, (1,2), axis=1)\n",
    "\n",
    "# Split by condition\n",
    "# Get rid of phase column\n",
    "csvIntSTCond = np.delete(csvIntSTCond, 2, axis = 1)\n",
    "# Split by informed/uninformed\n",
    "informedST = csvIntSTCond[csvIntSTCond[:,1]==0]\n",
    "uninformedST = csvIntSTCond[csvIntSTCond[:,1]==1]\n",
    "informedST = np.delete(informedST, 1, axis=1)\n",
    "uninformedST = np.delete(uninformedST, 1, axis=1)\n",
    "# Split by user\n",
    "splitInfST = [informedST[informedST[:,0]==i] for i in np.unique(informedST[:,0])]\n",
    "splitUniST = [uninformedST[uninformedST[:,0]==i] for i in np.unique(uninformedST[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the p(correct) at each trial per task and per user\n",
    "def extractProbsTrajec(arr, userArr):\n",
    "    # Store p(correct) per user\n",
    "    probUser = []\n",
    "    # Go through user\n",
    "    for u in range(userArr):\n",
    "        tmpU = arr[u]\n",
    "        # Init prior\n",
    "        alpha,bet = 2,2\n",
    "        # Store p(correct) = predicted accuracy evolution per task for user u\n",
    "        probTask = []\n",
    "        # Go through each task\n",
    "        for t in range(tasks):\n",
    "            # Split by task\n",
    "            tmpT = tmpU[tmpU[:,1] == t]\n",
    "            # Go through its trial history\n",
    "            succ = 0\n",
    "            # store p(correct) in this task\n",
    "            probs = []\n",
    "            probs.append(np.mean(beta(alpha+succ, bet+(0+1)-succ).rvs(size=500)))\n",
    "            #print(np.mean(beta(alpha+succ, bet+(0+1)-succ).rvs(size=500)), alpha+succ, bet+0-succ)\n",
    "            for trial in range(np.shape(tmpT)[0]):\n",
    "                # Check if the answer was correct on this trial\n",
    "                if tmpT[trial,2] == 1:\n",
    "                    succ+=1\n",
    "                #Construct beta distribution for posterior Beta(α=1+Succ, β=1+Trials−Succ)\n",
    "                dist = beta(alpha+succ, bet+(trial+1)-succ)\n",
    "                #Draw sample from beta distribution\n",
    "                #print(np.mean(dist.rvs(size=500)), alpha+succ, bet+(trial+1)-succ)\n",
    "                probs.append(np.mean(dist.rvs(size=500)))\n",
    "            probTask.append(probs)\n",
    "        probUser.append(probTask)\n",
    "    return np.asarray(probUser)\n",
    "\n",
    "# Obtain predicted accuracy (e.g. \"I predict based on my observations that my p(correct)=? if you ask me \n",
    "# to classify instances of this exercise without receiving any feedback\")\n",
    "probsFTTI = extractProbsTrajec(splitInfFTT, usersFTI)\n",
    "probsFTTU = extractProbsTrajec(splitUniFTT, usersFTU)\n",
    "probsSTI = extractProbsTrajec(splitInfST, usersSI)\n",
    "probsSTU = extractProbsTrajec(splitUniST, usersSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLP(probs, userArr):\n",
    "    lpsUser = []\n",
    "    # Go through every user and task\n",
    "    for u in range(userArr):\n",
    "        #tmpU = diff[u]\n",
    "        tmpU = probs[u]\n",
    "        lps = []\n",
    "        for t in range(tasks):\n",
    "            # Convert prob to errors\n",
    "            errT = 1-tmpU[t]\n",
    "            # Get err difference |e(t) - e(t-1)|^2\n",
    "            diffT = np.diff(errT)\n",
    "            # fit polinomial to error differences\n",
    "            slope, intercept = np.polyfit(np.arange(len(diffT)), diffT, 1)\n",
    "            x = np.linspace(0, len(diffT)-1, 100)\n",
    "            # LP = - [Fitted Error(present) - Fitted Error(past)]\n",
    "            lp = -((slope*x[-1]+intercept)-(slope*x[0]+intercept))\n",
    "            lps.append(lp)\n",
    "            #print(slope*x[0]+intercept, slope*x[-1]+intercept, diffT, lp)\n",
    "            #print(probs[u], errT, diffT, slope*x[0]+intercept, slope*x[-1]+intercept, lp)\n",
    "        lpsUser.append(lps)\n",
    "        \n",
    "        #print(lpsUser)\n",
    "    return np.asarray(lpsUser)\n",
    "\n",
    "# Get LP\n",
    "lpFTTI = getLP(probsFTTI, usersFTI)\n",
    "lpFTTU = getLP(probsFTTU, usersFTU)\n",
    "lpSTI = getLP(probsSTI, usersSI)\n",
    "lpSTU = getLP(probsSTU, usersSU)\n",
    "#print(np.shape(lpFTTI), lpFTTI)\n",
    "\n",
    "# Associate training LP to first selection\n",
    "fslpFTI = lpFTTI[np.arange(len(lpFTTI)), selFTI[0]]\n",
    "fslpFTU = lpFTTU[np.arange(len(lpFTTU)), selFTU[0]]\n",
    "fslpSI = lpSTI[np.arange(len(lpSTI)), selSI[0]]\n",
    "fslpSU = lpSTU[np.arange(len(lpSTU)), selSU[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLP(arr, label):\n",
    "    # Create bins (0 - 0.03 in 0.001 steps)\n",
    "    binsLP = np.arange(-0.16, 0.08, 0.02) \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # Normalize to sum 1\n",
    "    weights = np.ones_like(arr)/len(arr)\n",
    "    plt.hist(arr, bins=binsLP, weights=weights, edgecolor='black', linewidth=1.2)\n",
    "    #plt.hist(arr, bins=binsLP, edgecolor='black', linewidth=1.2)\n",
    "    \n",
    "    #plt.hist(performance, bins=binsPC, edgecolor='black', linewidth=1.2)\n",
    "    ax.set_title(''.join(['Task selection on the first trial wrt LP | ', label]))\n",
    "    ax.set_ylabel('Proportion')\n",
    "    ax.set_xlabel('LP')\n",
    "    ax.set_ylim([0,0.3])\n",
    "\n",
    "plotLP(fslpFTI, 'Train+Free Exp (Informed)')\n",
    "plotLP(fslpFTU, 'Train+Free Exp (Uninformed)')\n",
    "plotLP(fslpSI, 'Strategic (Informed)')\n",
    "plotLP(fslpSU, 'Strategic (Uninformed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal LP\n",
    "\n",
    "Fits a linear regressor to the error curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLPNormal(probs, userArr):\n",
    "    lpsUser = []\n",
    "    # Go through every user and task\n",
    "    for u in range(userArr):\n",
    "        #tmpU = diff[u]\n",
    "        tmpU = probs[u]\n",
    "        lps = []\n",
    "        for t in range(tasks):\n",
    "            # Convert prob to errors\n",
    "            errT = 1-tmpU[t]\n",
    "            # fit polinomial to error differences\n",
    "            slope, intercept = np.polyfit(np.arange(len(errT)), errT, 1)\n",
    "            x = np.linspace(0, len(errT)-1, 100)\n",
    "            # LP = - [Fitted Error(present) - Fitted Error(past)]\n",
    "            lp = -((slope*x[-1]+intercept)-(slope*x[0]+intercept))\n",
    "            lps.append(lp)\n",
    "            #print(slope*x[0]+intercept, slope*x[-1]+intercept, diffT, lp)\n",
    "            #print(probs[u], errT, diffT, slope*x[0]+intercept, slope*x[-1]+intercept, lp)\n",
    "        lpsUser.append(lps)\n",
    "        \n",
    "        #print(lpsUser)\n",
    "    return np.asarray(lpsUser)\n",
    "\n",
    "# Get LP\n",
    "lpFTTI_N = getLPNormal(probsFTTI, usersFTI)\n",
    "lpFTTU_N = getLPNormal(probsFTTU, usersFTU)\n",
    "lpSTI_N = getLPNormal(probsSTI, usersSI)\n",
    "lpSTU_N = getLPNormal(probsSTU, usersSU)\n",
    "#print(np.shape(lpFTTI), lpFTTI)\n",
    "\n",
    "# Associate training LP to first selection\n",
    "fslpFTI_N = lpFTTI_N[np.arange(len(lpFTTI_N)), selFTI[0]]\n",
    "fslpFTU_N = lpFTTU_N[np.arange(len(lpFTTU_N)), selFTU[0]]\n",
    "fslpSI_N = lpSTI_N[np.arange(len(lpSTI_N)), selSI[0]]\n",
    "fslpSU_N = lpSTU_N[np.arange(len(lpSTU_N)), selSU[0]]\n",
    "\n",
    "def plotLP(arr, label):\n",
    "    \n",
    "    #performance = checkPerformance(arr, firstSelec)\n",
    "    # Create bins (0 - 0.03 in 0.001 steps)\n",
    "    binsLP = np.arange(-0.3, 0.5, 0.1) \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # Normalize to sum 1\n",
    "    weights = np.ones_like(arr)/len(arr)\n",
    "    plt.hist(arr, bins=binsLP, weights=weights, edgecolor='black', linewidth=1.2)\n",
    "    #plt.hist(arr, bins=binsLP, edgecolor='black', linewidth=1.2)\n",
    "    \n",
    "    #plt.hist(performance, bins=binsPC, edgecolor='black', linewidth=1.2)\n",
    "    ax.set_title(''.join(['Task selection on the first trial wrt LP | ', label]))\n",
    "    ax.set_ylabel('Proportion')\n",
    "    ax.set_xlabel('LP')\n",
    "    ax.set_ylim([0,0.4])\n",
    "    \n",
    "plotLP(fslpFTI_N, 'Train+Free Exp (Informed)')\n",
    "plotLP(fslpFTU_N, 'Train+Free Exp (Uninformed)')\n",
    "plotLP(fslpSI_N, 'Strategic (Informed)')\n",
    "plotLP(fslpSU_N, 'Strategic (Uninformed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary LP\n",
    "\n",
    "Obtains Learning Progress based on fitting a line on correct (0) and incorrect (1) answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the p(correct) at each trial per task and per user\n",
    "def extractSuccTrajec(arr, userArr):\n",
    "    # Store p(correct) per user\n",
    "    succUser = []\n",
    "    # Go through user\n",
    "    for u in range(userArr):\n",
    "        tmpU = arr[u]\n",
    "        # Init prior\n",
    "        alpha,bet = 2,2\n",
    "        # Store p(correct) = predicted accuracy evolution per task for user u\n",
    "        succTask = []\n",
    "        # Go through each task\n",
    "        for t in range(tasks):\n",
    "            # Split by task\n",
    "            tmpT = tmpU[tmpU[:,1] == t]\n",
    "            # Go through its trial history\n",
    "            # store successes/errors in this task\n",
    "            succ = []\n",
    "            #print(np.mean(beta(alpha+succ, bet+(0+1)-succ).rvs(size=500)), alpha+succ, bet+0-succ)\n",
    "            for trial in range(np.shape(tmpT)[0]):\n",
    "                # Check if the answer was correct on this trial\n",
    "                if tmpT[trial,2] == 1:\n",
    "                    succ.append(0)\n",
    "                else:\n",
    "                    succ.append(1)\n",
    "            succTask.append(succ)\n",
    "        succUser.append(succTask)\n",
    "    return np.asarray(succUser)\n",
    "\n",
    "# Obtain predicted accuracy (e.g. \"I predict based on my observations that my p(correct)=? if you ask me \n",
    "# to classify instances of this exercise without receiving any feedback\")\n",
    "succFTTI = extractSuccTrajec(splitInfFTT, usersFTI)\n",
    "succFTTU = extractSuccTrajec(splitUniFTT, usersFTU)\n",
    "succSTI = extractSuccTrajec(splitInfST, usersSI)\n",
    "succSTU = extractSuccTrajec(splitUniST, usersSU)\n",
    "\n",
    "def getLPBinary(probs, userArr):\n",
    "    lpsUser = []\n",
    "    # Go through every user and task\n",
    "    for u in range(userArr):\n",
    "        #tmpU = diff[u]\n",
    "        tmpU = probs[u]\n",
    "        lps = []\n",
    "        for t in range(tasks):\n",
    "            # Convert prob to errors\n",
    "            errT = 1-tmpU[t]\n",
    "            # fit polinomial to error differences\n",
    "            slope, intercept = np.polyfit(np.arange(len(errT)), errT, 1)\n",
    "            x = np.linspace(0, len(errT)-1, 100)\n",
    "            # LP = - [Fitted Error(present) - Fitted Error(past)]\n",
    "            lp = -((slope*x[-1]+intercept)-(slope*x[0]+intercept))\n",
    "            lps.append(lp)\n",
    "            #print(slope*x[0]+intercept, slope*x[-1]+intercept, diffT, lp)\n",
    "            #print(probs[u], errT, diffT, slope*x[0]+intercept, slope*x[-1]+intercept, lp)\n",
    "        lpsUser.append(lps)\n",
    "        \n",
    "        #print(lpsUser)\n",
    "    return np.asarray(lpsUser)\n",
    "\n",
    "# Get LP\n",
    "lpFTTI_B = getLPBinary(succFTTI, usersFTI)\n",
    "lpFTTU_B = getLPBinary(succFTTU, usersFTU)\n",
    "lpSTI_B = getLPBinary(succSTI, usersSI)\n",
    "lpSTU_B = getLPBinary(succSTU, usersSU)\n",
    "#print(np.shape(lpFTTI), lpFTTI)\n",
    "\n",
    "# Associate training LP to first selection\n",
    "fslpFTI_B = lpFTTI_B[np.arange(len(lpFTTI_B)), selFTI[0]]\n",
    "fslpFTU_B = lpFTTU_B[np.arange(len(lpFTTU_B)), selFTU[0]]\n",
    "fslpSI_B = lpSTI_B[np.arange(len(lpSTI_B)), selSI[0]]\n",
    "fslpSU_B = lpSTU_B[np.arange(len(lpSTU_B)), selSU[0]]\n",
    "\n",
    "def plotLP(arr, label):\n",
    "    \n",
    "    #performance = checkPerformance(arr, firstSelec)\n",
    "    # Create bins (0 - 0.03 in 0.001 steps)\n",
    "    binsLP = np.arange(-1.2, 1.1, 0.2) \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # Normalize to sum 1\n",
    "    weights = np.ones_like(arr)/len(arr)\n",
    "    plt.hist(arr, bins=binsLP, weights=weights, edgecolor='black', linewidth=1.2)\n",
    "    #plt.hist(arr, bins=binsLP, edgecolor='black', linewidth=1.2)\n",
    "    \n",
    "    #plt.hist(performance, bins=binsPC, edgecolor='black', linewidth=1.2)\n",
    "    ax.set_title(''.join(['Task selection on the first trial wrt LP | ', label]))\n",
    "    ax.set_ylabel('Proportion')\n",
    "    ax.set_xlabel('LP')\n",
    "    #ax.set_ylim([0,0.37])\n",
    "    \n",
    "plotLP(fslpFTI_B, 'Train+Free Exp (Informed)')\n",
    "plotLP(fslpFTU_B, 'Train+Free Exp (Uninformed)')\n",
    "plotLP(fslpSI_B, 'Strategic (Informed)')\n",
    "plotLP(fslpSU_B, 'Strategic (Uninformed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='A7'></a>\n",
    "## A7 - Relative Learning Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relative training LP of the first task selected\n",
    "def checkRelativeLP(lps, firstSelecLP):\n",
    "    # Get average LP per user for the four tasks\n",
    "    means = np.mean(lps, axis=1)\n",
    "    # Normalize the LP of the task that was selected in relation to the mean\n",
    "    normlp = firstSelecLP/means\n",
    "    return normlp\n",
    "\n",
    "def plotRelativeLP(arr, firstSelec, label, bin_min=-3.0, bin_max=3.3, bin_step=0.25):\n",
    "    \n",
    "    relLP = checkRelativeLP(arr, firstSelec)\n",
    "    \n",
    "    # Create bins (0 - 1 in 0.1 steps)\n",
    "    #binsLP = np.linspace(0,2.1,22)\n",
    "    binsLP = np.arange(bin_min, bin_max, bin_step) \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    # Normalize to sum 1\n",
    "    weights = np.ones_like(relLP)/len(relLP)\n",
    "    #plt.hist(performance, bins=binsPC, weights=weights, edgecolor='black', linewidth=1.2)\n",
    "    plt.hist(relLP, bins=binsLP, weights=weights, edgecolor='black', linewidth=1.2)\n",
    "    \n",
    "    #plt.hist(performance, bins=binsPC, edgecolor='black', linewidth=1.2)\n",
    "    ax.set_title(''.join(['Task selection on the first trial wrt relative LP | ', label]))\n",
    "    ax.set_ylabel('Proportion')\n",
    "    ax.set_ylim([0,0.2])\n",
    "    \n",
    "plotRelativeLP(lpFTTI,fslpFTI, 'Train+Free Exp (Informed)')\n",
    "plotRelativeLP(lpFTTU,fslpFTU, 'Train+Free Exp (Uninformed)')\n",
    "plotRelativeLP(lpSTI,fslpSI, 'Strategic (Informed)')\n",
    "plotRelativeLP(lpSTU,fslpSU, 'Strategic (Uninformed)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
