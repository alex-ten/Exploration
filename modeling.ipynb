{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import comb\n",
    "from scipy.stats import rankdata, pearsonr\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import colors as COLORS\n",
    "\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "from scipy.special import comb\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interact, Layout\n",
    "from IPython import display\n",
    "\n",
    "import loc_utils as lut\n",
    "import vis_utils as vut\n",
    "from standards import *\n",
    "\n",
    "rx = RAWXix()\n",
    "r = RAWix()\n",
    "gcolors = ['#008fd5', '#fc4f30', '#e5ae38', '#6d904f']\n",
    "colors = ['#375e97', '#f18d9e', '#ffbb00', '#3f681c']\n",
    "glabels = {0: 'F', 1: 'S'}\n",
    "clabels = {0: 'i-', 1: 'i+'}\n",
    "\n",
    "def gclabel(g, c):\n",
    "    return '{}/{}'.format(glabels[g], clabels[c])\n",
    "\n",
    "tlabels = {\n",
    "        1: '1D',\n",
    "        2: 'I1D',\n",
    "        3: '2D',\n",
    "        4: 'R'}\n",
    "\n",
    "saveloc = '/Users/alexten/Projects/HFSP/img'\n",
    "desktop = '/Users/alexten/Desktop/'\n",
    "\n",
    "data_path = 'pipeline_data/s3/joint_data.pkl'\n",
    "\n",
    "def save_it(fig, savedir, figname, save_as='svg', dpi=500, compress=True):\n",
    "    s = savedir+'/{}.{}'.format(figname, save_as)\n",
    "    fig.savefig(s, format=save_as, dpi=500)\n",
    "    if compress:\n",
    "        os.system('scour -i {} -o {}'.format(s, s.replace('img', 'img_compressed')))\n",
    "        \n",
    "def onehot(ind):\n",
    "    ind = ind - 1\n",
    "    onehots = np.zeros([ind.size, 4])\n",
    "    onehots[np.arange(ind.size), ind] = 1\n",
    "    return onehots\n",
    "\n",
    "\n",
    "def run_MNlog(x, y, pivot, fullout=0):\n",
    "    y = y.replace(to_replace=pivot, value=0, inplace=False)\n",
    "    mdl = sm.MNLogit(y, x)\n",
    "    mdl_fit = mdl.fit(maxiter=100, full_output=fullout)\n",
    "    return mdl_fit\n",
    "\n",
    "def run_skl_MNlog(x, y, pivot):\n",
    "    # y = y.replace(to_replace=pivot, value=0, inplace=False)\n",
    "    mdl = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "    mdl_fit = mdl.fit(x, y)\n",
    "    return mdl_fit\n",
    "\n",
    "\n",
    "def softmax(x, stable=0):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    if stable:\n",
    "        e_x = np.exp(x - np.max(x, axis=0))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "\n",
    "def add_text(ax, arr):\n",
    "    for (j, i), label in np.ndenumerate(arr):\n",
    "        ax.text(i, j, label, ha='center', va='center')\n",
    "        \n",
    "# cols = 'sid,grp,stage,trial,blkt,t0,t1,pc1,pc2,pc3,pc4,p1,p2,p3,p4,sc1,sc2,sc3,sc4,sw_pred,sw_act,sw_lag'.split(',')\n",
    "# ix = cols.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Prepare data\n",
    "\n",
    "Look at the accuracy of your switch predictions as a function of how far they are from the last switch that the person made. For this, take the switch predictions that do not involve a dip below the learning threshold (easier to interpret!). Then assign each switch prediction to a “lag” relative to the last task switch the person made. For instance, if the person just switched tasks on trial 10, and your prediction is that he should switch again on trial 11, this switch command has a lag of 1 trial; if your prediction was that he should switch again on trial 12, this has a lag of 2 trials; and so on. Plot the % of switch predictions that were obeyed as a function of lag. This will give you an estimate of how long after a switch people need in order to switch again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def self_challenging_data(path, alpha=.01, null=.5, save_as=False):\n",
    "    def p_val(n, k, p):\n",
    "        return comb(n,k) * p**k * (1-p)**(n-k)\n",
    "\n",
    "    mdata = lut.unpickle(path)['main']\n",
    "    sids, groups, tasks = lut.get_unique(mdata, [r.ix('sid'), r.ix('group'),r.ix('cat')])\n",
    "\n",
    "    nontest = freeplay = lut.get_mask(mdata, {r.ix('stage'): 2}, '!=')\n",
    "    mdata = mdata[nontest, :]\n",
    "\n",
    "    outdata = []\n",
    "    cols = 'sid,grp,stage,trial,blkt,t0,t1,pc1,pc2,pc3,pc4,p1,p2,p3,p4,sc1,sc2,sc3,sc4,sw_pred,sw_act,sw_lag'.split(',')\n",
    "    ix = cols.index\n",
    "\n",
    "    for grp in groups:\n",
    "        gmask = lut.get_mask(mdata, {r.ix('group'): grp})\n",
    "        gsids = lut.get_unique(mdata[gmask,:], r.ix('sid'))\n",
    "        \n",
    "        for sid in gsids:\n",
    "            sdata = mdata[lut.get_mask(mdata, {r.ix('sid'): sid}), :]\n",
    "            sid_data = np.zeros([sdata.shape[0]-1, len(cols)])\n",
    "            \n",
    "            # fill in task on next trial\n",
    "            sid_data[:, ix('t1')] = sdata[:, r.ix('cat')][1:]\n",
    "            \n",
    "            # discard the last trial completely\n",
    "            sdata = sdata[:-1, :]\n",
    "            \n",
    "            # fill in group, sid, stage, and actual switches\n",
    "            sid_data[:,ix('sid')] = sdata[:, r.ix('sid')]\n",
    "            sid_data[:,ix('grp')] = grp\n",
    "            sid_data[:,ix('stage')] = sdata[:, r.ix('stage')]\n",
    "            sid_data[:-1,ix('sw_act')] = sdata[:, r.ix('switch')][1:]\n",
    "            sid_data[:60,ix('sw_act')] = 0\n",
    "            \n",
    "            # fill in trial numbers and block trial numbers\n",
    "            sid_data[:, ix('trial')] = sdata[:, r.ix('trial')]\n",
    "            sid_data[:, ix('blkt')] = sdata[:, r.ix('blkt')]\n",
    "            \n",
    "            # fill in task on current trial\n",
    "            sid_data[:, ix('t0')] = sdata[:, r.ix('cat')]\n",
    "            \n",
    "            for ti, tsk in enumerate(tasks):\n",
    "                tmask = lut.get_mask(sdata, {r.ix('cat'): tsk})\n",
    "                \n",
    "                trials_so_far = np.cumsum(tmask)\n",
    "                cor_on_task = np.zeros(sid_data.shape[0])\n",
    "                cor_on_task[tmask] = sdata[tmask, r.ix('cor')]\n",
    "                cor_so_far = np.cumsum(cor_on_task)\n",
    "                \n",
    "                with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                    sid_data[:, ix('pc{}'.format(tsk))] = cor_so_far / trials_so_far\n",
    "                    sid_data[:, ix('p{}'.format(tsk))] = p_val(\n",
    "                        trials_so_far, cor_so_far, null)\n",
    "            sid_data = sid_data[58:]\n",
    "\n",
    "            pcs = sid_data[:, ix('pc1'):ix('p1')].copy()\n",
    "            pvals = sid_data[:, ix('p1'):ix('sc1')]\n",
    "            \n",
    "            t1 = sid_data[:, ix('t1')].astype(int)-1\n",
    "            t0 = sid_data[:, ix('t0')].astype(int)-1\n",
    "            \n",
    "            actual_next_choice = np.zeros([sid_data.shape[0], 4]).astype(bool)\n",
    "            actual_next_choice[np.arange(t1.size), t1] = True\n",
    "            \n",
    "            learnt = np.logical_and(pvals < alpha, pcs > null)\n",
    "            learnt_pcs = pcs.copy()\n",
    "            learnt_pcs[learnt] -= 1\n",
    "            predicted_pc = sid_data[\n",
    "                np.arange(sid_data.shape[0]), \n",
    "                ix('pc1')+np.argmax(learnt_pcs, axis=1)]\n",
    "            \n",
    "            sid_data[1:, ix('sw_pred')] = np.logical_not(\n",
    "                t0[1:]==np.argmax(pcs, axis=1)[:-1])\n",
    "            \n",
    "            sw_lag_mask = np.logical_and(\n",
    "                sid_data[:, ix('sw_pred')], pvals[np.arange(t0.size), t0] >= alpha)\n",
    "            sid_data[:, ix('sw_lag')] = sid_data[:, ix('blkt')]\n",
    "            sid_data[:2, ix('sw_lag')], sid_data[:, ix('sw_lag')][~sw_lag_mask] = np.nan, np.nan\n",
    "            \n",
    "            all_four = np.all(learnt, axis=1)\n",
    "            for tsk in tasks:\n",
    "                sid_data[all_four, ix('sc{}'.format(tsk))] = np.nan\n",
    "            sid_data[all_four, ix('sw_pred')] = np.nan\n",
    "            \n",
    "            sid_data[1:, ix('sc1'):ix('sc4')+1] = predicted_pc[1:].reshape([-1,1]) - pcs[1:]\n",
    "            \n",
    "            outdata.append(sid_data[1:])\n",
    "            \n",
    "#             if grp == 0 and sid == 72:\n",
    "#                 sid_data = sid_data[1:]\n",
    "#                 fig = plt.figure(300)\n",
    "#                 ax = fig.add_subplot(111)\n",
    "#                 m = np.logical_and(sid_data[:, ix('sw_act')].astype(bool), sid_data[:, ix('sw_pred')].astype(bool))\n",
    "#                 mm = ~np.isnan(sid_data[:, ix('sw_lag')]) & m\n",
    "#                 trials = np.nonzero(mm)\n",
    "#                 lags = sid_data[:, ix('sw_lag')][mm]\n",
    "#                 print('Lags: {}\\nTrials: {}'.format(lags, trials))\n",
    "#                 ax.set_color_cycle(colors)\n",
    "#                 ax.plot(sid_data[:, ix('pc1'):ix('pc4')+1])\n",
    "#                 ax.plot(sid_data[:, ix('p1'):ix('p4')+1], ls='--')\n",
    "#                 ax.vlines(np.nonzero(~np.isnan(sid_data[:, ix('sw_lag')])),0,1,color='purple', alpha=.4)\n",
    "#                 ax.plot(sid_data[:, ix('sw_act')], ls='', c='cyan', marker='s',alpha=.5)\n",
    "#                 ax.plot(np.arange(m.size),m, ls='', marker='|', color='k', alpha=.5)\n",
    "            \n",
    "            \n",
    "    outdata = np.vstack(outdata)\n",
    "    \n",
    "    if save_as:\n",
    "        lut.dopickle(save_as, outdata)\n",
    "\n",
    "        \n",
    "if 1:\n",
    "    save_as = 'pipeline_data/scdata/modeling_data_sw_lag.pkl'\n",
    "    \n",
    "    self_challenging_data(path='pipeline_data/s3/joint_data.pkl',\n",
    "                      save_as=save_as)\n",
    "\n",
    "# cyan squares = actual switches\n",
    "# purple vertical lines = lagging trials\n",
    "# black ticks = prediction obeying switches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Visualize swithcing as a function of lag\n",
    "### Switch lag distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def view_switching_vs_lag(path, figname):\n",
    "    data = lut.unpickle(path)\n",
    "    \n",
    "    cols = 'sid,grp,stage,trial,blkt,t0,t1,pc1,pc2,pc3,pc4,p1,p2,p3,p4,sc1,sc2,sc3,sc4,sw_pred,sw_act,sw_lag'.split(',')\n",
    "    ix = cols.index\n",
    "    \n",
    "    sids, groups = lut.get_unique(data, [ix('sid'), ix('grp')])\n",
    "    tasks = [1,2,3,4]\n",
    "    \n",
    "    fig = plt.figure(num=figname)\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    all_lags = []\n",
    "    for grp in groups:\n",
    "        gmask = lut.get_mask(data, {ix('grp'): grp})\n",
    "        gsids = lut.get_unique(data[gmask,:], ix('sid'))\n",
    "        \n",
    "        for gsid in gsids:\n",
    "            smask = lut.get_mask(data, {ix('sid'): gsid})\n",
    "            sid_data = data[smask, :]\n",
    "\n",
    "            m = np.logical_and(sid_data[:, ix('sw_act')].astype(bool), sid_data[:, ix('sw_pred')].astype(bool))\n",
    "            mm = ~np.isnan(sid_data[:, ix('sw_lag')]) & m\n",
    "\n",
    "            if np.any(mm):\n",
    "                all_lags.append(sid_data[:, ix('sw_lag')][mm].mean())\n",
    "        \n",
    "        vut.line_histogram(ax, np.array(all_lags), np.arange(0,250,10), glabels[grp], lw=2, c=gcolors[grp])\n",
    "    ax.legend()\n",
    "    ax.set_title('Switch lags seem similar ')\n",
    "\n",
    "    \n",
    "def view_switching_vs_lag_boxplot(path, figname):\n",
    "    data = lut.unpickle(path)\n",
    "    \n",
    "    cols = 'sid,grp,stage,trial,blkt,t0,t1,pc1,pc2,pc3,pc4,p1,p2,p3,p4,sc1,sc2,sc3,sc4,sw_pred,sw_act,sw_lag'.split(',')\n",
    "    ix = cols.index\n",
    "    \n",
    "    sids, groups = lut.get_unique(data, [ix('sid'), ix('grp')])\n",
    "    tasks = [1,2,3,4]\n",
    "    \n",
    "    fig = plt.figure(num=figname)\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    test_data = []\n",
    "    for grp in groups:\n",
    "        glags = []\n",
    "        gmask = lut.get_mask(data, {ix('grp'): grp})\n",
    "        gsids = lut.get_unique(data[gmask,:], ix('sid'))\n",
    "        \n",
    "        for gsid in gsids:\n",
    "            smask = lut.get_mask(data, {ix('sid'): gsid})\n",
    "            sid_data = data[smask, :]\n",
    "\n",
    "            m = np.logical_and(sid_data[:, ix('sw_act')].astype(bool), sid_data[:, ix('sw_pred')].astype(bool))\n",
    "            mm = ~np.isnan(sid_data[:, ix('sw_lag')]) & m\n",
    "            \n",
    "            if np.any(mm):\n",
    "                glags.append(sid_data[:, ix('sw_lag')][mm].mean())\n",
    "        \n",
    "        test_data.append(glags)\n",
    "        gmean = np.mean(glags)\n",
    "        gsem = stats.sem(glags)\n",
    "        ax.bar(grp, gmean, yerr=gsem, align='center', facecolor=gcolors[grp],\n",
    "               ecolor='k', capsize=10, label=glabels[grp])\n",
    "\n",
    "    ax.set_xticks(groups)\n",
    "    ax.set_xticklabels(['Free', 'Strategic'])\n",
    "    ax.set_title('Switch lags are smaller in Strategic group (alt)')\n",
    "    ax.grid(True, linestyle=':', c='gray', zorder=0)\n",
    "    vut.despine(ax, ['top','right'])\n",
    "    \n",
    "    W, levene = stats.levene(test_data[0], test_data[1], center='mean')\n",
    "    print(W,levene, np.var(test_data[0]), np.var(test_data[1]))\n",
    "    print(stats.ttest_ind(test_data[0], test_data[1], equal_var=levene >= .05))\n",
    "    \n",
    "if 1:\n",
    "    view_switching_vs_lag('pipeline_data/scdata/modeling_data_sw_lag.pkl', figname = 'switching_and_lag')\n",
    "    \n",
    "    view_switching_vs_lag_boxplot('pipeline_data/scdata/modeling_data_sw_lag.pkl', figname = 'switching_and_lag_bars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Average streak lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def view_streak_lengths(path, figname):\n",
    "    data = lut.unpickle(path)\n",
    "    \n",
    "    cols = 'sid,grp,stage,trial,blkt,t0,t1,pc1,pc2,pc3,pc4,p1,p2,p3,p4,sc1,sc2,sc3,sc4,sw_pred,sw_act,sw_lag'.split(',')\n",
    "    ix = cols.index\n",
    "    \n",
    "    sids, groups = lut.get_unique(data, [ix('sid'), ix('grp')])\n",
    "    tasks = [1,2,3,4]\n",
    "    \n",
    "    fig = plt.figure(num=figname)\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    test_data = []\n",
    "    for grp in groups:\n",
    "        streaks = []\n",
    "        mean_streaks = []\n",
    "        \n",
    "        gmask = lut.get_mask(data, {ix('grp'): grp})\n",
    "        gsids = lut.get_unique(data[gmask, :], ix('sid'))\n",
    "        for gsid in gsids:\n",
    "            smask = lut.get_mask(data, {ix('sid'): gsid})\n",
    "            sid_data = data[smask, :]\n",
    "            \n",
    "            switch = sid_data[:, ix('sw_act')].astype(bool)\n",
    "            streaks += sid_data[:, ix('blkt')][switch].tolist()\n",
    "            \n",
    "            mean_streaks.append(np.mean(sid_data[:, ix('blkt')][switch]))\n",
    "            \n",
    "        test_data.append(streaks)\n",
    "        gmean = np.mean(streaks)\n",
    "        gsem = stats.sem(streaks)\n",
    "        ax.bar(grp, gmean, yerr=gsem, align='center', facecolor=gcolors[grp],\n",
    "               ecolor='k', capsize=10, label=glabels[grp])\n",
    "\n",
    "    ax.set_xticks(groups)\n",
    "    ax.set_xticklabels(['Free', 'Strategic'])\n",
    "    ax.set_title('Streak lengths by group')\n",
    "    ax.grid(True, linestyle=':', c='gray', zorder=0)\n",
    "    vut.despine(ax, ['top','right'])\n",
    "    \n",
    "    print(np.var(test_data[0]), np.var(test_data[1]))\n",
    "    print(stats.ttest_ind(test_data[0], test_data[1]))\n",
    "    \n",
    "    \n",
    "if 1:\n",
    "    view_streak_lengths('pipeline_data/scdata/modeling_data_sw_lag.pkl', figname='streak lengths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0.0,
     3.0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sigm(x):\n",
    "    return (1)/(1 + np.exp(-x))\n",
    "\n",
    "def pval_on_switch(path, subj, k):\n",
    "    np.set_printoptions(suppress=True)\n",
    "    data = lut.unpickle(path)\n",
    "    sids, groups = lut.get_unique(data, [ix('sid'), ix('grp')])\n",
    "    \n",
    "    # fig = plt.figure('pvals_n_switches', figsize=[7,4])\n",
    "    # ax = fig.add_subplot(111)\n",
    "    \n",
    "    for grp in groups[:1]:\n",
    "        gmask = lut.get_mask(data, {ix('grp'): grp})\n",
    "        gsids = lut.get_unique(data[gmask, :], ix('sid'))\n",
    "        \n",
    "        bs = []\n",
    "        for sid in gsids[subj:subj+1]:\n",
    "            smask = lut.get_mask(data, {ix('sid'): sid})\n",
    "            nrows = smask.sum()\n",
    "            \n",
    "            switch_trials = data[smask, ix('sw_act')].astype(int)\n",
    "            \n",
    "            blkt = data[smask, ix('blkt')]\n",
    "            pvals = data[smask, ix('p1'):ix('sc')]\n",
    "\n",
    "            t0 = data[smask, ix('t0')] - 1\n",
    "\n",
    "            pvals = pvals[np.arange(nrows), t0.astype(int)]\n",
    "            \n",
    "            Y = switch_trials[:k].reshape([-1, 1])\n",
    "            \n",
    "            # Only pvals\n",
    "            X = pvals[:k].reshape([-1, 1])*100\n",
    "            X = sm.add_constant(X)\n",
    "            logit_model = sm.Logit(Y, X)\n",
    "            try:\n",
    "                results = logit_model.fit(disp=0)\n",
    "            except np.linalg.LinAlgError as err:\n",
    "                continue\n",
    "            print(results.summary())\n",
    "            \n",
    "            # Only blkt\n",
    "            X = blkt[:k].reshape([-1, 1])\n",
    "            X = sm.add_constant(X)\n",
    "            logit_model = sm.Logit(Y, X)\n",
    "            try:\n",
    "                results = logit_model.fit(disp=0)\n",
    "            except np.linalg.LinAlgError as err:\n",
    "                continue\n",
    "            print(results.summary())\n",
    "\n",
    "            # pvals and blkt\n",
    "            X = np.stack([blkt[:k], pvals[:k]*100], axis=1)\n",
    "            X = sm.add_constant(X)\n",
    "            logit_model = sm.Logit(Y, X)\n",
    "            try:\n",
    "                results = logit_model.fit(disp=0)\n",
    "            except np.linalg.LinAlgError as err:\n",
    "                continue\n",
    "            print(results.summary())\n",
    "            \n",
    "#             x = np.sum(\n",
    "#                 np.stack([bi*xi for bi, xi in zip(results.params, X.T)], axis=0), axis=0)\n",
    "#             y = sigm(x)\n",
    "\n",
    "#             inds = np.arange(k)\n",
    "#             ax2.plot(inds,y, c=gcolors[1], lw=1, marker='o', markersize=2, alpha=.5)\n",
    "#             ax2.plot(inds,pvals[:k], c=gcolors[0], lw=1)\n",
    "#             for i in inds[switch_trials.astype(bool)[:k]]:\n",
    "#                 ax2.axvline(i, c='k', alpha=.2, zorder=0)\n",
    "#             error = np.mean((y-Y.squeeze())**2)\n",
    "\n",
    "#             print('Mean squared error =', error)\n",
    "#             for p, ci in zip(results.params, results.conf_int()):\n",
    "#                 print(np.exp(p), np.exp(ci))\n",
    "            \n",
    "#     pvals = data[np.arange(data.shape[0]), data[ix('p1')+ix('t0')-1].astype(int)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 1:\n",
    "    pval_on_switch('pipeline_data/scdata/modeling_data.pkl', 8, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0.0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def softmax(x, axis=0):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x, axis=axis).reshape([-1,1]))\n",
    "    return e_x / e_x.sum(axis=axis).reshape([-1,1])\n",
    "\n",
    "def get_vars(path, subj, k, figname=''):\n",
    "    \n",
    "    cols = 'sid,grp,stage,trial,blkt,t0,t1,pc1,pc2,pc3,pc4,p1,p2,p3,p4,sc1,sc2,sc3,sc4,switch,sw_act'.split(',')\n",
    "    ix = cols.index\n",
    "    \n",
    "    np.set_printoptions(suppress=True, threshold=5000)\n",
    "    data = lut.unpickle(path)\n",
    "    sids, groups = lut.get_unique(data, [ix('sid'), ix('grp')])\n",
    "    \n",
    "#     fig = plt.figure(figname, figsize=[8,10])\n",
    "#     ax1 = fig.add_subplot(311)\n",
    "#     ax1.set_ylim(-.05, 1)\n",
    "#     ax1.set_ylabel('PC')\n",
    "    \n",
    "#     ax2 = fig.add_subplot(312)\n",
    "# #     ax2.set_ylim(-.05, 1)\n",
    "#     ax2.set_ylabel('Relative challenge')\n",
    "    \n",
    "#     axlast = fig.add_subplot(313)\n",
    "    \n",
    "# #     for grp in groups[:1]:\n",
    "#         gmask = lut.get_mask(data, {ix('grp'): grp})\n",
    "#         gsids = lut.get_unique(data[gmask, :], ix('sid'))\n",
    "        \n",
    "#         for sid in gsids[subj:subj+1]:\n",
    "    smask = lut.get_mask(data, {ix('sid'): subj})\n",
    "    sdata = data[smask, :][:k]\n",
    "\n",
    "    pc  = sdata[:, ix('pc1'):ix('pc4')+1]\n",
    "    ch  = sdata[:, ix('sc1'):ix('sc4')+1]\n",
    "    rts = np.zeros_like(pc)\n",
    "    for j, tsk in enumerate([1,2,3,4]):\n",
    "        tmask = lut.get_mask(sdata, {ix('t0'): tsk})\n",
    "        rts[tmask, j] = 1\n",
    "    rts[0, :] = 15\n",
    "    rts = np.cumsum(rts, axis=0)\n",
    "    rts = np.transpose(rts.T / np.sum(rts, axis=1))\n",
    "    \n",
    "    return pc, ch, rts, sdata\n",
    "\n",
    "#             for ti, tsk in enumerate([1,2,3,4]):\n",
    "#                 tmask = lut.get_mask(sdata, {ix('t0'): tsk})\n",
    "\n",
    "#                 trials = sdata[tmask, ix('trial')]\n",
    "                \n",
    "#                 # AX 1\n",
    "#                 pcs = sdata[:, ix('pc{}'.format(tsk))]\n",
    "#                 ax1.plot(np.arange(60, 60+pcs.size), pcs, c=colors[ti], lw=2, alpha=.7,\n",
    "#                        label=tlabels[tsk])\n",
    "\n",
    "#                 # AX 2\n",
    "#                 sc = sdata[:, ix('sc{}'.format(tsk))]\n",
    "\n",
    "#                 ax2.plot(np.arange(60, 60+pcs.size), sc, c=colors[ti], lw=2, alpha=.7,\n",
    "#                        label=tlabels[tsk])\n",
    "                \n",
    "# #                 x, y = np.arange(60, 60+pcs.size).astype(float), np.zeros(pcs.size).astype(float)\n",
    "# #                 x[~tmask], y[~tmask] = np.nan, np.nan\n",
    "# #                 ax1.fill_between(x, y-.1, color=colors[ti], lw=2, alpha=.7,\n",
    "# #                        label=tlabels[tsk])\n",
    "\n",
    "#                 # AX LAST\n",
    "#                 x, y = np.arange(60, 60+pcs.size).astype(float), np.zeros(pcs.size).astype(float)\n",
    "#                 x[~tmask], y[~tmask] = np.nan, np.nan\n",
    "#                 axlast.plot(x, y, color=colors[ti], lw=1, alpha=.7,\n",
    "#                        label=tlabels[tsk], marker='|')\n",
    "                \n",
    "# #                 axlast.plot(x, y, c=colors[ti], lw=2, alpha=.7,\n",
    "# #                        label=tlabels[tsk])\n",
    "                \n",
    "                \n",
    "def update(lc, x1, x2, x3, b1, b2, b3):\n",
    "    lincomb = b1*x1 + b2*x2 + b3*x3\n",
    "    v = softmax(lincomb, 1)\n",
    "    ptskv = np.argmax(v, axis=1)\n",
    "    lc_pred.set_array(ptskv)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "if 1:\n",
    "    path = 'pipeline_data/scdata/modeling_data_sc_by_task.pkl'\n",
    "    lim = 250\n",
    "    sid = np.random.randint(0,150)\n",
    "    print(sid)\n",
    "    \n",
    "    x1, x2, x3, raw = get_vars(path, sid, lim)\n",
    "    style = {'width': '80%'}\n",
    "    b1 = widgets.FloatSlider(value=1, min=-10, max=10, step=.1, description='PC', continuous_update=False, layout=Layout(width='400px'))\n",
    "    b2 = widgets.FloatSlider(value=1, min=-10, max=10, step=.1, description='Ch', continuous_update=False, layout=Layout(width='400px'))\n",
    "    b3 = widgets.FloatSlider(value=1, min=-10, max=10, step=.1, description='RTS', continuous_update=False, layout=Layout(width='400px'))\n",
    "    \n",
    "    fig = plt.figure('Interactive model', figsize=[8,4])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim(0, lim)\n",
    "    ax.set_ylim(0, 1)\n",
    "    cmap = mpl.colors.ListedColormap(colors)\n",
    "    norm = mpl.colors.BoundaryNorm(range(5), cmap.N)\n",
    "    \n",
    "    \n",
    "    tskv = raw[:, ix('t0')]-1\n",
    "    ypos = np.zeros(lim)\n",
    "    inds = np.arange(lim)\n",
    "    \n",
    "    points = np.array([inds, ypos+.2]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "    lc_act = mpl.collections.LineCollection(segments, cmap=cmap, norm=norm, linewidth=10)\n",
    "    lc_act.set_array(tskv)\n",
    "    ax.add_collection(lc_act)\n",
    "    \n",
    "    points = np.array([inds, ypos+.4]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "    lc_pred = mpl.collections.LineCollection(segments, cmap=cmap, norm=norm, linewidth=10)\n",
    "\n",
    "    lincomb = b1.value*x1 + b2.value*x2 + b3.value*x3\n",
    "    v = softmax(lincomb, 1)\n",
    "    ptskv = np.argmax(v, axis=1)\n",
    "    lc_pred.set_array(ptskv)\n",
    "    ax.add_collection(lc_pred)\n",
    "    \n",
    "    interact(update, \n",
    "             lc=widgets.fixed(lc_pred), \n",
    "             x1=widgets.fixed(x1),\n",
    "             x2=widgets.fixed(np.abs(x2)),\n",
    "             x3=widgets.fixed(x3),\n",
    "             b1=b1, b2=b2, b3=b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1.089765\n",
      "         Iterations: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-9.63580312e-03 -9.78689892e-03 -1.64220449e-02  1.12047276e-03\n",
      "   3.44277879e+00 -3.39394155e+00 -6.19810864e-03 -4.26222451e-02]\n",
      " [-1.53161876e-02 -9.49403187e-03  1.77470744e-03 -2.62448852e-03\n",
      "   3.39627135e+00 -3.76346592e-03 -3.39015149e+00 -2.36710539e-03]\n",
      " [-1.52903916e-02 -1.97280769e-02  1.04833492e-01  1.19984419e-03\n",
      "   3.10164528e+00  8.58924808e-02  1.64386407e-01 -3.35191125e+00]]\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                 Choice   No. Observations:                  962\n",
      "Model:                        MNLogit   Df Residuals:                      938\n",
      "Method:                           MLE   Df Model:                           21\n",
      "Date:                Mon, 08 Oct 2018   Pseudo R-squ.:                  0.2129\n",
      "Time:                        16:11:34   Log-Likelihood:                -1048.4\n",
      "converged:                      False   LL-Null:                       -1331.9\n",
      "                                        LLR p-value:                1.265e-106\n",
      "==============================================================================\n",
      "  Choice=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "pc            -0.0113      0.014     -0.822      0.411      -0.038       0.016\n",
      "sc            -0.0104      0.009     -1.096      0.273      -0.029       0.008\n",
      "rt             0.0500      0.132      0.380      0.704      -0.208       0.308\n",
      "sl             0.0012      0.004      0.277      0.782      -0.007       0.010\n",
      "t1            68.0046        nan        nan        nan         nan         nan\n",
      "t2           -12.2270   5.62e+06  -2.18e-06      1.000    -1.1e+07     1.1e+07\n",
      "t3            12.7058   5.57e+06   2.28e-06      1.000   -1.09e+07    1.09e+07\n",
      "t4            12.5888   5.61e+06   2.24e-06      1.000    -1.1e+07     1.1e+07\n",
      "const        -13.2529   5.57e+06  -2.38e-06      1.000   -1.09e+07    1.09e+07\n",
      "------------------------------------------------------------------------------\n",
      "  Choice=3       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "pc            -0.0183      0.013     -1.452      0.146      -0.043       0.006\n",
      "sc            -0.0099      0.009     -1.065      0.287      -0.028       0.008\n",
      "rt             0.0704      0.135      0.521      0.602      -0.194       0.335\n",
      "sl            -0.0024      0.004     -0.551      0.582      -0.011       0.006\n",
      "t1            65.5642   4.61e+06   1.42e-05      1.000   -9.03e+06    9.03e+06\n",
      "t2            10.3234        nan        nan        nan         nan         nan\n",
      "t3           -11.8284        nan        nan        nan         nan         nan\n",
      "t4            10.1785        nan        nan        nan         nan         nan\n",
      "const        -10.7952        nan        nan        nan         nan         nan\n",
      "------------------------------------------------------------------------------\n",
      "  Choice=4       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "pc            -0.0193      0.013     -1.532      0.126      -0.044       0.005\n",
      "sc            -0.0205      0.009     -2.228      0.026      -0.039      -0.002\n",
      "rt             0.1954      0.139      1.405      0.160      -0.077       0.468\n",
      "sl             0.0014      0.004      0.330      0.741      -0.007       0.010\n",
      "t1            44.1919        nan        nan        nan         nan         nan\n",
      "t2           -10.6995        nan        nan        nan         nan         nan\n",
      "t3           -10.6801        nan        nan        nan         nan         nan\n",
      "t4           -15.5923        nan        nan        nan         nan         nan\n",
      "const          7.2200        nan        nan        nan         nan         nan\n",
      "==============================================================================\n",
      "[[0.144 0.017 0.29  0.447]\n",
      " [0.09  0.325 0.294 0.275]\n",
      " [0.077 0.275 0.387 0.24 ]\n",
      " [0.068 0.196 0.08  0.691]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/statsmodels/discrete/discrete_model.py:2970: RuntimeWarning: invalid value encountered in sqrt\n",
      "  bse = np.sqrt(np.diag(self.cov_params()))\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "def model1(path):\n",
    "    cols = 'sid,grp,stage,trial,blkt,t0,t1,pc1,pc2,pc3,pc4,p1,p2,p3,p4,sc1,sc2,sc3,sc4,switch,sw_act'.split(',')\n",
    "    ix = cols.index\n",
    "    \n",
    "    data = lut.unpickle(path)\n",
    "\n",
    "    sids, groups = lut.get_unique(data, [ix('sid'), ix('grp')])\n",
    "    tasks = [1, 2, 3, 4]\n",
    "\n",
    "#     fig = plt.figure(num='Model summary', figsize=[12, 8])\n",
    "    images = []\n",
    "    \n",
    "    for grp in groups[:1]:\n",
    "\n",
    "        gmask = lut.get_mask(arr=data, conds={ix('grp'): grp})\n",
    "        gdata = data[gmask, :]\n",
    "        switch = gdata[:, ix('sw_act')].astype(bool)\n",
    "        \n",
    "        gdata = gdata[switch, :]\n",
    "        \n",
    "        pc = gdata[:, ix('pc1'):ix('pc4') + 1]\n",
    "        ch = gdata[:, ix('sc1'):ix('sc4') + 1]\n",
    "        \n",
    "        blkt = gdata[:, ix('blkt')]\n",
    "        rt = np.zeros_like(pc)\n",
    "\n",
    "        for j, tsk in enumerate([1, 2, 3, 4]):\n",
    "            tmask = lut.get_mask(gdata, {ix('t0'): tsk})\n",
    "            rt[tmask, j] = 1\n",
    "\n",
    "        rt[0, :] = 15\n",
    "        rt = np.cumsum(rt, axis=0)\n",
    "        rt = np.transpose(rt.T / np.sum(rt, axis=1))\n",
    "\n",
    "        ind = onehot(gdata[:, ix('t0')].astype(int)).astype(bool)\n",
    "        t1dv = ind[:, 0].reshape([-1, 1]).astype(float)\n",
    "        t2dv = ind[:, 1].reshape([-1, 1]).astype(float)\n",
    "        t3dv = ind[:, 2].reshape([-1, 1]).astype(float)\n",
    "        t4dv = ind[:, 3].reshape([-1, 1]).astype(float)\n",
    "        \n",
    "#         pcv = pc[ind].reshape([-1, 1])*100\n",
    "#         scv = ch[ind].reshape([-1, 1])*100\n",
    "#         suv = blkt[ind].reshape([-1, 1])\n",
    "#         rtv = rt[ind].reshape([-1, 1])*100\n",
    "\n",
    "        x1 = pc[ind].reshape([-1, 1])*100\n",
    "        x2 = ch[ind].reshape([-1, 1])*100\n",
    "        x3 = rt[ind].reshape([-1, 1])*100\n",
    "        x4 = blkt.reshape([-1, 1])\n",
    "        \n",
    "        X_array = np.concatenate([x1, x2, x3, x4, t1dv, t2dv, t3dv, t4dv], 1)\n",
    "        X = sm.add_constant(X_array, prepend=False)\n",
    "        X = pd.DataFrame(data=X, columns='pc,sc,rt,sl,t1,t2,t3,t4,const'.split(','))\n",
    "\n",
    "        Y = pd.DataFrame(data=gdata[:, ix('t1')].astype(int), columns=['Choice'])\n",
    "\n",
    "        N = 100\n",
    "        exrt = np.linspace(0, 1, 265)\n",
    "        expc = [.4, .6, .8, 1.0]\n",
    "\n",
    "        softmax_weights = []\n",
    "        const_mat = []\n",
    "        pc_mat = []\n",
    "        rt_mat = []\n",
    "\n",
    "        z = np.zeros(X.shape[1])\n",
    "        for ti, tsk in enumerate(tasks[:1]):\n",
    "            model = run_MNlog(X, Y, pivot=tsk, fullout=1)\n",
    "            model2 = run_skl_MNlog(X_array, Y, pivot=tsk)\n",
    "            \n",
    "            beta_ = model.params.T\n",
    "            beta_2 = model2.coef_\n",
    "            \n",
    "            print(beta_2 - beta_2[0, :])\n",
    "            softmax_weights.append(-np.sum(beta_, axis=1))\n",
    "\n",
    "            beta_ = np.insert(beta_.values, ti, z, axis=0)\n",
    "            const_mat.append(beta_[:, -1])\n",
    "            pc_mat.append(beta_[:, 0])\n",
    "            rt_mat.append(beta_[:, 1])\n",
    "\n",
    "            # Predict\n",
    "            if 0:\n",
    "                logits = np.dot(beta_, X.T)\n",
    "                Y_hat = np.argmax(softmax(logits, stable=1), axis=0)\n",
    "\n",
    "            if ti > -1:\n",
    "                print(model.summary())\n",
    "\n",
    "        overall = np.stack(softmax_weights, axis=1).T\n",
    "        onevrest_const = np.stack(const_mat, axis=0)\n",
    "        onevrest_pc = np.stack(pc_mat, axis=0)\n",
    "        onevrest_rt = np.stack(rt_mat, axis=0)\n",
    "\n",
    "        overall = np.stack(softmax_weights, axis=1).T\n",
    "        onevrest_const = np.stack(const_mat, axis=0)\n",
    "        onevrest_pc = np.stack(pc_mat, axis=0)\n",
    "        onevrest_rt = np.stack(rt_mat, axis=0)\n",
    "\n",
    "#         ax2 = fig.add_subplot(2, 3, 1 + grp * 3)\n",
    "#         odds = np.exp(onevrest_pc)\n",
    "#         images.append(ax2.matshow(odds, aspect='equal', cmap='viridis'))\n",
    "#         ax2.set_title('Group {}: OvR PC'.format('FS'[grp]), pad=20)\n",
    "#         ax2.xaxis.set_ticks_position('top')\n",
    "#         ax2.yaxis.set_ticks_position('left')\n",
    "#         ax2.set_xticks([0, 1, 2, 3])\n",
    "#         ax2.set_yticks([0, 1, 2, 3])\n",
    "#         ax2.set_xticklabels('1D,I1D,2D,R'.split(','))\n",
    "#         ax2.set_yticklabels('1D,I1D,2D,R'.split(','))\n",
    "#         ax2.set_ylabel('Reference')\n",
    "#         ax2.set_xlabel('Odds: Pr(task)/P(reference)')\n",
    "#         add_text(ax2, np.around(odds, 3))\n",
    "\n",
    "#         ax3 = fig.add_subplot(2, 3, 2 + grp * 3)\n",
    "#         odds = np.exp(onevrest_rt)\n",
    "#         images.append(ax3.matshow(odds, aspect='equal', cmap='viridis'))\n",
    "#         ax3.set_title('Group {}: OvR RT'.format('FS'[grp]), pad=20)\n",
    "#         ax3.xaxis.set_ticks_position('top')\n",
    "#         ax3.yaxis.set_ticks_position('left')\n",
    "#         ax3.set_xticks([0, 1, 2, 3])\n",
    "#         ax3.set_yticks([0, 1, 2, 3])\n",
    "#         ax3.set_xticklabels('1D,I1D,2D,R'.split(','))\n",
    "#         ax3.set_yticklabels('1D,I1D,2D,R'.split(','))\n",
    "#         ax3.set_ylabel('Reference')\n",
    "#         ax3.set_xlabel('Odds: Pr(task)/Pr(reference)')\n",
    "#         add_text(ax3, np.around(odds, 3))\n",
    "\n",
    "        logits = np.dot(beta_, X.T)\n",
    "        Y_hat = np.argmax(softmax(logits, stable=1), axis=0) + 1\n",
    "        CM = confusion_matrix(Y.values.squeeze(), Y_hat)\n",
    "#         ERR = \n",
    "        CM = np.around(CM / CM.sum(axis=1), 3)\n",
    "        print(CM)\n",
    "\n",
    "#         ax4 = fig.add_subplot(2, 3, 3 + grp * 3)\n",
    "#         ax4.matshow(CM, aspect='equal', cmap=plt.cm.Blues, vmin=0, vmax=1)\n",
    "#         ax4.set_title('Group {}: Confusion matrix'.format('FS'[grp]), pad=20)\n",
    "#         ax4.xaxis.set_ticks_position('top')\n",
    "#         ax4.yaxis.set_ticks_position('left')\n",
    "#         ax4.set_xticks([0, 1, 2, 3])\n",
    "#         ax4.set_yticks([0, 1, 2, 3])\n",
    "#         ax4.set_xticklabels('1D,I1D,2D,R'.split(','))\n",
    "#         ax4.set_yticklabels('1D,I1D,2D,R'.split(','))\n",
    "#         ax4.set_ylabel('Observed')\n",
    "#         ax4.set_xlabel('Predicted')\n",
    "#         add_text(ax4, CM)\n",
    "\n",
    "# #         lut.dopickle('/Users/alexten/Projects/Exploration/model_weights_group{}'.format(grp), beta_)\n",
    "\n",
    "#         # print('Predictions:')\n",
    "#         # output = softmax(np.dot(beta, examples), stable=True)\n",
    "#         # print(np.around(output[:, ii], 5))\n",
    "\n",
    "#     # Find the min and max of all colors for use in setting the color scale.\n",
    "#     vmin = 0 #min(image.get_array().min() for image in images)\n",
    "#     vmax = 2 #max(image.get_array().max() for image in images)\n",
    "#     norm = COLORS.Normalize(vmin=vmin, vmax=vmax)\n",
    "#     for im in images:\n",
    "#         im.set_norm(norm)\n",
    "\n",
    "#     # fig.colorbar(images[0], ax=axs, orientation='horizontal', fraction=.1)\n",
    "\n",
    "#     # Make images respond to changes in the norm of other images (e.g. via the\n",
    "#     # \"edit axis, curves and images parameters\" GUI on Qt), but be careful not to\n",
    "#     # recurse infinitely!\n",
    "#     def update(changed_image):\n",
    "#         for im in images:\n",
    "#             if (changed_image.get_cmap() != im.get_cmap()\n",
    "#                     or changed_image.get_clim() != im.get_clim()):\n",
    "#                 im.set_cmap(changed_image.get_cmap())\n",
    "#                 im.set_clim(changed_image.get_clim())\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     fig.subplots_adjust(hspace=.3)\n",
    "    # save_it(fig, '/Users/alexten/Projects/HFSP/img', 'MNLogit_pc_rt', save_as='svg', dpi=500, compress=True)\n",
    "\n",
    "#         lut.dopickle('/Users/alexten/Projects/Exploration/model_weights_group{}'.format(grp), beta_)\n",
    "\n",
    "\n",
    "#     # fig.colorbar(images[0], ax=axs, orientation='horizontal', fraction=.1)\n",
    "\n",
    "#     # Make images respond to changes in the norm of other images (e.g. via the\n",
    "#     # \"edit axis, curves and images parameters\" GUI on Qt), but be careful not to\n",
    "#     # recurse infinitely!\n",
    "#     def update(changed_image):\n",
    "#         for im in images:\n",
    "#             if (changed_image.get_cmap() != im.get_cmap()\n",
    "#                     or changed_image.get_clim() != im.get_clim()):\n",
    "#                 im.set_cmap(changed_image.get_cmap())\n",
    "#                 im.set_clim(changed_image.get_clim())\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     fig.subplots_adjust(hspace=.3)\n",
    "#     # save_it(fig, '/Users/alexten/Projects/HFSP/img', 'MNLogit_pc_rt', save_as='svg', dpi=500, compress=True)\n",
    "    \n",
    "    \n",
    "if 1:\n",
    "    model1(path='pipeline_data/scdata/modeling_data_sw_lag.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
