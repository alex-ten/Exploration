{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T15:12:11.165405Z",
     "start_time": "2019-03-04T15:12:08.417841Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm_notebook as progbar\n",
    "from collections import deque, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cycler import cycler\n",
    "from scipy.stats import rankdata\n",
    "import os\n",
    "\n",
    "import loc_utils as lut\n",
    "import vis_utils as vut\n",
    "from standards import *\n",
    "\n",
    "rx = RAWXix()\n",
    "r = RAWix()\n",
    "\n",
    "colors = ['#008fd5', '#fc4f30', '#e5ae38', '#6d904f']\n",
    "\n",
    "glabels = {0: 'F', 1: 'S'}\n",
    "clabels = {0: 'i-', 1: 'i+'}\n",
    "\n",
    "def gclabel(g, c):\n",
    "    return '{}/{}'.format(glabels[g], clabels[c])\n",
    "\n",
    "tlabels = {\n",
    "        1: '1D',\n",
    "        2: 'I1D',\n",
    "        3: '2D',\n",
    "        4: 'R'}\n",
    "\n",
    "saveloc = '/Users/alexten/Projects/HFSP/img'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Split subjects by learning and performance\n",
    "## 1.1. Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T15:39:58.233212Z",
     "start_time": "2019-03-04T15:39:52.008564Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g0 c0: 75\n",
      "g0 c1: 79\n",
      "g1 c0: 84\n",
      "g1 c1: 92\n",
      "Total: 330\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e4e41f0876446ea98e8538994bebea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Data', max=330), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:83: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File pipeline_data/split_data/split_data_v0-15-15_clean.pkl exists. Overwrite? [y/n]\n",
      ">>> y\n",
      "Overwriting data to pipeline_data/split_data/split_data_v0-15-15_clean.pkl\n",
      "Done saving.\n"
     ]
    }
   ],
   "source": [
    "path = 'pipeline_data/s3/joint_data.pkl'\n",
    "\n",
    "train_window_0 = 5\n",
    "train_window_1 = 15\n",
    "test_window = 15\n",
    "test_stage_data = False\n",
    "\n",
    "save_as = 'pipeline_data/split_data/split_data_v{}-{}-{}_clean.pkl'.format(int(test_stage_data), train_window_1, test_window)\n",
    "\n",
    "if 1:\n",
    "    from s3_remove_outliers import remove_by_sid, report_analysis\n",
    "    \n",
    "    mdata = lut.unpickle(path)['main']\n",
    "    lut.report_subject_counts(mdata)\n",
    "\n",
    "    tasks, groups, sids = lut.get_unique(mdata, [r.ix(c) for c in ['cat', 'group', 'sid']])\n",
    "    tasks = tasks[0:-1]\n",
    "    \n",
    "    sids_col = []\n",
    "    groups_col = []\n",
    "    conds_col = []\n",
    "    testsize_col = []\n",
    "    teststart_col = []\n",
    "    task_col = []\n",
    "    train_pc_0 = []\n",
    "    train_pc_1 = []\n",
    "    test_pc = []\n",
    "    \n",
    "#     # Locally, check for outliers (those who didn't play at least `test_widnow` times on free play)\n",
    "#     outliers = []\n",
    "#     if test_stage_data:\n",
    "#         g0 = lut.get_mask(mdata, {r.ix('group'): 0})\n",
    "#         sids_g0 = lut.get_unique(mdata[g0,:], r.ix('sid'))\n",
    "#         for sid in progbar(sids_g0, desc='1. Outliers:'):\n",
    "#             for tsk in tasks:\n",
    "#                 mask = lut.get_mask(mdata, {r.ix('sid'): sid, r.ix('stage'): 1, r.ix('cat'): tsk})\n",
    "#                 if np.sum(mask) < test_window:\n",
    "#                     outliers.append(sid)\n",
    "#     else:\n",
    "#         for sid in progbar(sids, desc='Outliers:'):\n",
    "#             for tsk in tasks:\n",
    "#                 mask = lut.get_mask(mdata, {r.ix('sid'): sid, \n",
    "#                                             r.ix('stage'): 1, \n",
    "#                                             r.ix('cat'): tsk})\n",
    "#                 if np.sum(mask) < test_window:\n",
    "#                     outliers.append(sid)\n",
    "                    \n",
    "\n",
    "#     mdata = remove_by_sid(mdata, list(set(outliers)), assign_new_ids=False)\n",
    "#     lut.report_subject_counts(mdata)\n",
    "#     report_analysis('Filtering by min trials during free play', outliers)\n",
    "    \n",
    "    sids = lut.get_unique(mdata, r.ix('sid'))\n",
    "    for sid in progbar(sids, desc='Data'):\n",
    "        subject_mask = lut.get_mask(mdata, {r.ix('sid'):sid})\n",
    "        grp = mdata[subject_mask, r.ix('group')][0]\n",
    "        cnd = mdata[subject_mask, r.ix('cond')][0]\n",
    "        ii = 1 if test_stage_data*grp else 0\n",
    "        \n",
    "        for tsk in tasks:\n",
    "#             # Compute test data\n",
    "#             mask = lut.get_mask(mdata, {r.ix('sid'): sid, r.ix('stage'): 1 + ii, r.ix('cat'): tsk})\n",
    "#             test = mdata[mask, r.ix('cor')]\n",
    "#             test_pc.append(np.mean(test[-test_window:]))\n",
    "#             testsize_col.append(test.size)\n",
    "#             teststart_col.append(mdata[mask, r.ix('trial')][-test_window])\n",
    "            \n",
    "            # Compute train data\n",
    "            mask = lut.get_mask(mdata, {r.ix('sid'): sid, r.ix('stage'): 0, r.ix('cat'): tsk})\n",
    "            train = mdata[mask, r.ix('cor')]\n",
    "            train_pc_0.append(np.mean(train[:train_window_0]))\n",
    "            train_pc_1.append(np.mean(train[-train_window_1:]))\n",
    "\n",
    "            # Record epi data\n",
    "            groups_col.append(grp)\n",
    "            conds_col.append(cnd)\n",
    "            sids_col.append(sid)\n",
    "            task_col.append(tsk)\n",
    "            \n",
    "    \n",
    "    data = np.stack(\n",
    "        map(np.array, [groups_col, sids_col, conds_col, task_col, \n",
    "                       train_pc_0, train_pc_1]\n",
    "           )).T\n",
    "    \n",
    "    if save_as:\n",
    "        lut.dopickle(save_as, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. View learning and performance distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T15:43:03.706649Z",
     "start_time": "2019-03-04T15:43:03.421607Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 6)\n",
      "           cond  train_pc0  train_pc1\n",
      "group                                \n",
      "0.0    0.512987   0.584416   0.646176\n",
      "1.0    0.522727   0.607197   0.666540\n"
     ]
    }
   ],
   "source": [
    "sp = ''\n",
    "v = 0\n",
    "train_window = 15\n",
    "test_window = 15\n",
    "split = 'group'\n",
    "prec = 2\n",
    "# saveloc = '/Users/alexten/Desktop'\n",
    "\n",
    "path = 'pipeline_data/split_data/split_data_v{}-{}-{}_clean.pkl'.format(v, train_window, test_window)\n",
    "# path = 'pipeline_data/split_data/split_data_v{}-{}-{}_clean.pkl'.format(v, 15, 15)\n",
    "\n",
    "figname = 'train test delta hists {} {}'.format(train_window, test_window).replace(' ', '_')\n",
    "save_as = ''\n",
    "\n",
    "figsize=[11, 11]\n",
    "rows = 4\n",
    "cols = 4\n",
    "plt.rc('axes', prop_cycle=cycler('color', ['#008fd5', '#fc4f30', '#e5ae38', '#6d904f', '#8b8b8b', '#810f7c']))\n",
    "plt.rc('lines', linewidth=2)\n",
    "ylim = .42\n",
    "\n",
    "\n",
    "if 1:\n",
    "    ix = ['group', 'sid', 'cond', 'task', 'train_pc', 'test_pc'].index\n",
    "    data = lut.unpickle(path)[:, [0, 1, 2, 3, 4, 5]]\n",
    "    print(data.shape)\n",
    "    df = pd.DataFrame(data, columns=['group', 'sid', 'cond', 'task', 'train_pc0', 'train_pc1'])\n",
    "    \n",
    "    df = df.set_index(['group','sid','task'])\n",
    "    \n",
    "    grouped = df.groupby(['group', 'sid']).mean().groupby('group').mean()\n",
    "    \n",
    "    print(grouped)\n",
    "    \n",
    "    \n",
    "#     fig = plt.figure(num=figname.split('/')[-1].replace('_', ' '), figsize=figsize)\n",
    "#     gs = mpl.gridspec.GridSpec(tasks.size + 1, 4)\n",
    "    \n",
    "#     for ti, tsk in enumerate(tasks):\n",
    "#         g0 = lut.get_mask(data, {ix(split): 0, ix('task'): tsk})\n",
    "#         g1 = lut.get_mask(data, {ix(split): 1, ix('task'): tsk})\n",
    "        \n",
    "#         train_pc = [data[g0, ix('train_pc')], data[g1, ix('train_pc')]]\n",
    "#         test_pc = [data[g0, ix('test_pc')], data[g1, ix('test_pc')]]\n",
    "#         delta_pc = [b - a for a, b in zip(train_pc, test_pc)]\n",
    "        \n",
    "#         lax = fig.add_subplot(gs[ti, 0])\n",
    "#         midax = fig.add_subplot(gs[ti, 1])\n",
    "#         rax = fig.add_subplot(gs[ti, 2:])\n",
    "        \n",
    "#         lax.set_ylabel('Relative frequency')\n",
    "#         lax.set_xlim(0, 1.05)\n",
    "#         lax.set_ylim(-.05, ylim)\n",
    "        \n",
    "#         midax.set_xlim(0, 1.05)\n",
    "#         midax.set_ylim(-.05, ylim)\n",
    "        \n",
    "#         rax.set_xlim(-1., 1.05)\n",
    "#         rax.set_ylim(-.05, ylim)\n",
    "        \n",
    "#         rax.axvline(0, c='k', alpha=.7, ls='--', lw=1)\n",
    "#         for i, (pc0, pc1, dpc) in enumerate(zip(train_pc, test_pc, delta_pc)):\n",
    "#             b0 = np.arange(0, 1.01 + 1/train_window, 1/train_window, dtype=pc0.dtype)\n",
    "#             b1 = np.arange(0, 1.01 + 1/test_window, 1/test_window, dtype=pc1.dtype)\n",
    "#             b2 = np.array(\n",
    "#                 np.array([-i for i in reversed(b0[1:-1].tolist())]+b0.tolist(), dtype=dpc.dtype)\n",
    "#             )\n",
    "#             vut.line_histogram(lax, pc0, b0, glabels[i], prec, lw=2)\n",
    "#             vut.line_histogram(midax, pc1, b1, glabels[i], prec, lw=2)\n",
    "#             vut.line_histogram(rax, dpc, b2, glabels[i], prec, lw=2)\n",
    "        \n",
    "#         for ax, b in zip([lax, midax, rax], [b0, b1, b2]):\n",
    "            \n",
    "#             ax.legend(loc=2)\n",
    "#             ax.set_title(tlabels[tsk])\n",
    "#             ax.set_xticklabels(np.around(b,2), rotation=90)\n",
    "#             ax.xaxis.set_major_formatter(mpl.ticker.FormatStrFormatter('%.2f'))\n",
    "\n",
    "    \n",
    "#     # ==================== bottom row =======================\n",
    "#     lax = fig.add_subplot(gs[3, 0])\n",
    "#     midax = fig.add_subplot(gs[3, 1])\n",
    "#     rax = fig.add_subplot(gs[3, 2:])\n",
    "\n",
    "#     lax.set_xlim(0, 1.05)\n",
    "#     lax.set_ylim(-.02, ylim)\n",
    "\n",
    "#     midax.set_xlim(0, 1.05)\n",
    "#     midax.set_ylim(-.02, ylim)\n",
    "\n",
    "#     rax.set_xlim(-1., 1.05)\n",
    "#     rax.set_ylim(-.02, ylim)\n",
    "\n",
    "#     rax.axvline(0, c='k', alpha=.7, ls='--', lw=1)\n",
    "    \n",
    "#     for ax, b in zip([lax, midax, rax], [b0, b1, b2]):\n",
    "#         ax.set_title('1D, I1D, 2D combined')\n",
    "#         ax.set_xticklabels(np.around(b,2), rotation=90)\n",
    "#         ax.xaxis.set_major_formatter(mpl.ticker.FormatStrFormatter('%.2f'))\n",
    "        \n",
    "#         lax.set_ylabel('Relative frequency')\n",
    "#         lax.set_xlabel('PC training')\n",
    "#         midax.set_xlabel('PC test')\n",
    "#         rax.set_xlabel('delta PC')\n",
    "        \n",
    "#     for grp in groups:\n",
    "#         gmask = lut.get_mask(data, {ix(split): grp})\n",
    "#         train_pc = data[gmask, ix('train_pc')]\n",
    "#         test_pc = data[gmask, ix('test_pc')]\n",
    "#         delta_pc = test_pc - train_pc\n",
    "\n",
    "#         vut.line_histogram(lax, train_pc, b0, glabels[grp], prec, lw=2); lax.legend(loc=2)\n",
    "#         vut.line_histogram(midax, test_pc, b1, glabels[grp], prec, lw=2); midax.legend(loc=2)\n",
    "#         vut.line_histogram(rax, delta_pc, b2, glabels[grp], prec, lw=2); rax.legend(loc=2)\n",
    "#         rax.axvline(delta_pc, color=colors[grp])\n",
    "#     # ==================== bottom row =======================    \n",
    "        \n",
    "#     fig.tight_layout()   \n",
    "#     fig.subplots_adjust(hspace=.5)\n",
    "    # train_window = 15\n",
    "    # test_window = 15\n",
    "#     fig.suptitle(\n",
    "#         '({}) train {} (N bins = {}), test {} (N bins = {})'.format(sp, \n",
    "#                                                        train_window, b0.size-1,\n",
    "#                                                        test_window, b1.size-1), \n",
    "#         fontsize=16)\n",
    "    \n",
    "    if save_as:\n",
    "        s = saveloc+'/{}_{}.{}'.format(figname, sp, save_as)\n",
    "        fig.savefig(s, format=save_as, dpi=500)\n",
    "        os.system('scour -i {} -o {}'.format(s, s.replace('img', 'img_compressed')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bins(start, step, N):\n",
    "    return [start + (step * i) for i in range(N + 2)]\n",
    "\n",
    "n=10\n",
    "make_bins(0, 1/n, n)[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([0,0,0,1,1,1,1,1,1,1], dtype=np.float32)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
